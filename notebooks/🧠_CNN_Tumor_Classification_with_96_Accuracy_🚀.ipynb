{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 2645886,
          "sourceType": "datasetVersion",
          "datasetId": 1608934
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "🧠 CNN Tumor Classification with 96% Accuracy 🚀",
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "masoudnickparvar_brain_tumor_mri_dataset_path = kagglehub.dataset_download('masoudnickparvar/brain-tumor-mri-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "7BhDqsJLEaLx"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-11T19:49:26.800384Z",
          "iopub.execute_input": "2025-03-11T19:49:26.800722Z",
          "iopub.status.idle": "2025-03-11T19:49:38.107058Z",
          "shell.execute_reply.started": "2025-03-11T19:49:26.800678Z",
          "shell.execute_reply": "2025-03-11T19:49:38.10603Z"
        },
        "id": "GMuxTRuHEaLz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.initializers import HeUniform, GlorotUniform\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as npa\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix , accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, LeakyReLU\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import losses\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-11T19:49:38.107978Z",
          "iopub.execute_input": "2025-03-11T19:49:38.108379Z",
          "iopub.status.idle": "2025-03-11T19:49:52.344819Z",
          "shell.execute_reply.started": "2025-03-11T19:49:38.108354Z",
          "shell.execute_reply": "2025-03-11T19:49:52.344055Z"
        },
        "id": "aRuUPCVgEaL0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📌 1. Path Identification"
      ],
      "metadata": {
        "id": "tVfXvDikEaL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "data_dir = pathlib.Path(r\"/kaggle/input/brain-tumor-mri-dataset/\")\n",
        "\n",
        "train_dir = '/kaggle/input/brain-tumor-mri-dataset/Training'\n",
        "test_dir = '/kaggle/input/brain-tumor-mri-dataset/Testing'\n",
        "\n",
        "\n",
        "# Method 2: You can try forward slash"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-11T19:51:35.409769Z",
          "iopub.execute_input": "2025-03-11T19:51:35.410171Z",
          "iopub.status.idle": "2025-03-11T19:51:35.414511Z",
          "shell.execute_reply.started": "2025-03-11T19:51:35.410142Z",
          "shell.execute_reply": "2025-03-11T19:51:35.413513Z"
        },
        "id": "0LqKczahEaL4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📌 2. Data Preprocessing with ImageDataGenerator"
      ],
      "metadata": {
        "id": "kt3uqnyUEaL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-11T19:51:37.514947Z",
          "iopub.execute_input": "2025-03-11T19:51:37.515334Z",
          "iopub.status.idle": "2025-03-11T19:51:37.519662Z",
          "shell.execute_reply.started": "2025-03-11T19:51:37.515305Z",
          "shell.execute_reply": "2025-03-11T19:51:37.518491Z"
        },
        "id": "BI5kMCSuEaL5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📌 3. Defining Train & Test Folders"
      ],
      "metadata": {
        "id": "lE2WlG8WEaL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = str(data_dir / \"Training\")\n",
        "test_dir = str(data_dir / \"Testing\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-11T19:51:37.778602Z",
          "iopub.execute_input": "2025-03-11T19:51:37.778993Z",
          "iopub.status.idle": "2025-03-11T19:51:37.783102Z",
          "shell.execute_reply.started": "2025-03-11T19:51:37.778961Z",
          "shell.execute_reply": "2025-03-11T19:51:37.782032Z"
        },
        "id": "Wk1K8NKpEaL6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📌 4. Define Image Size & Batch Size for Model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-11T19:51:51.391404Z",
          "iopub.execute_input": "2025-03-11T19:51:51.391749Z",
          "iopub.status.idle": "2025-03-11T19:51:51.39583Z",
          "shell.execute_reply.started": "2025-03-11T19:51:51.391725Z",
          "shell.execute_reply": "2025-03-11T19:51:51.39468Z"
        },
        "id": "yeJ1Wiu8EaL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 240\n",
        "img_width = 240"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-11T19:52:14.481423Z",
          "iopub.execute_input": "2025-03-11T19:52:14.481776Z",
          "iopub.status.idle": "2025-03-11T19:52:14.486158Z",
          "shell.execute_reply.started": "2025-03-11T19:52:14.48175Z",
          "shell.execute_reply": "2025-03-11T19:52:14.485061Z"
        },
        "id": "d2LL_gs6EaL7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📌 5. Loading Training and Test Datasets"
      ],
      "metadata": {
        "id": "7f4YKylOEaL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (img_height , img_width),\n",
        "    batch_size= batch_size,\n",
        "    class_mode = \"categorical\"\n",
        "    )\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (img_height , img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = \"categorical\"\n",
        "\n",
        "    )\n",
        "\n",
        "print(r\"Class Label :\" , train_generator.class_indices)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-11T19:52:47.971909Z",
          "iopub.execute_input": "2025-03-11T19:52:47.97229Z",
          "iopub.status.idle": "2025-03-11T19:52:50.33311Z",
          "shell.execute_reply.started": "2025-03-11T19:52:47.972261Z",
          "shell.execute_reply": "2025-03-11T19:52:50.332201Z"
        },
        "id": "exchENmwEaL8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATA PREPROCESSING SUMMARY\n",
        "\n",
        "🚀 What Does the Code Do in Brief?\n",
        "\n",
        "* Determines the dataset folder (data_dir).\n",
        "\n",
        "* Creates an ImageDataGenerator to rescale the images.\n",
        "\n",
        "* Determines the training (train_dir) and test (test_dir) data paths.\n",
        "\n",
        "* Resize the images to 240x240 and load them with flow_from_directory().\n",
        "\n",
        "* Prints the class labels."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-11T19:53:03.701581Z",
          "iopub.execute_input": "2025-03-11T19:53:03.702031Z",
          "iopub.status.idle": "2025-03-11T19:53:03.706619Z",
          "shell.execute_reply.started": "2025-03-11T19:53:03.701991Z",
          "shell.execute_reply": "2025-03-11T19:53:03.705461Z"
        },
        "id": "1nfYBEIkEaL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Is it necessary to use ❗to_categorical?❗\n",
        "\n",
        "No, there is no need to use to_categorical, because flow_from_directory(class_mode=\"categorical\") already automatically converts the tags to one-hot encoding format."
      ],
      "metadata": {
        "id": "Md90nsTsEaL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📌 6. VISUALIZATION"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-11T19:54:23.825662Z",
          "iopub.execute_input": "2025-03-11T19:54:23.826061Z",
          "iopub.status.idle": "2025-03-11T19:54:23.83011Z",
          "shell.execute_reply.started": "2025-03-11T19:54:23.826035Z",
          "shell.execute_reply": "2025-03-11T19:54:23.828738Z"
        },
        "id": "W66dIymGEaL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class_labels = list(train_generator.class_indices.keys())\n",
        "class_counts = [len(train_generator.filepaths) // train_generator.num_classes] * len(class_labels)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(class_labels, class_counts, color='skyblue')\n",
        "plt.xlabel(\"Classes\")\n",
        "plt.ylabel(\"Number of Samples\")\n",
        "plt.title(\"Class Distribution in Dataset\")\n",
        "plt.xticks(rotation=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-11T19:54:59.863096Z",
          "iopub.execute_input": "2025-03-11T19:54:59.86343Z",
          "iopub.status.idle": "2025-03-11T19:55:00.13972Z",
          "shell.execute_reply.started": "2025-03-11T19:54:59.863408Z",
          "shell.execute_reply": "2025-03-11T19:55:00.138673Z"
        },
        "id": "ZmmX1tw6EaL9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_batch, y_batch = next(train_generator)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(6):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(x_batch[i])\n",
        "    plt.title(f\"Class: {np.argmax(y_batch[i])}\")\n",
        "    plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-11T19:55:11.363481Z",
          "iopub.execute_input": "2025-03-11T19:55:11.363841Z",
          "iopub.status.idle": "2025-03-11T19:55:12.087449Z",
          "shell.execute_reply.started": "2025-03-11T19:55:11.363814Z",
          "shell.execute_reply": "2025-03-11T19:55:12.086385Z"
        },
        "id": "E3kUpnutEaL-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📌 7.LET'S DEVELOP THE MODEL"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-11T19:55:38.991082Z",
          "iopub.execute_input": "2025-03-11T19:55:38.991459Z",
          "iopub.status.idle": "2025-03-11T19:55:38.995481Z",
          "shell.execute_reply.started": "2025-03-11T19:55:38.991432Z",
          "shell.execute_reply": "2025-03-11T19:55:38.994344Z"
        },
        "id": "iItLiYJtEaL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-11T19:56:04.002506Z",
          "iopub.execute_input": "2025-03-11T19:56:04.002868Z",
          "iopub.status.idle": "2025-03-11T19:56:04.008137Z",
          "shell.execute_reply.started": "2025-03-11T19:56:04.002844Z",
          "shell.execute_reply": "2025-03-11T19:56:04.007024Z"
        },
        "id": "vMPIYYBREaL_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32 , (5,5) , activation=\"relu\" ,padding=\"valid\", kernel_initializer=HeUniform()),\n",
        "    MaxPooling2D(2,2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(64 , (5,5) , activation=\"relu\" ,padding=\"valid\", kernel_initializer=HeUniform()),\n",
        "    MaxPooling2D(2,2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(128 , (5,5) , activation=\"relu\" ,padding=\"valid\", kernel_initializer=HeUniform()),\n",
        "    MaxPooling2D(2,2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(64 , activation=\"relu\" , kernel_initializer=HeUniform()),\n",
        "    Dropout(0.2),\n",
        "    BatchNormalization(),\n",
        "    Dense(128 , activation=\"relu\" , kernel_initializer=HeUniform()),\n",
        "    Dropout(0.2),\n",
        "    BatchNormalization(),\n",
        "    Dense(256 , activation=\"relu\" , kernel_initializer=HeUniform()),\n",
        "    Dropout(0.3),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Dense(4 , activation=\"softmax\" , kernel_initializer=GlorotUniform()),\n",
        "\n",
        "    ])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-11T19:56:09.294701Z",
          "iopub.execute_input": "2025-03-11T19:56:09.295187Z",
          "iopub.status.idle": "2025-03-11T19:56:10.195822Z",
          "shell.execute_reply.started": "2025-03-11T19:56:09.295156Z",
          "shell.execute_reply": "2025-03-11T19:56:10.195089Z"
        },
        "id": "RcdY9V0QEaL_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001) , loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-11T19:56:14.560751Z",
          "iopub.execute_input": "2025-03-11T19:56:14.561132Z",
          "iopub.status.idle": "2025-03-11T19:56:14.583646Z",
          "shell.execute_reply.started": "2025-03-11T19:56:14.561102Z",
          "shell.execute_reply": "2025-03-11T19:56:14.582637Z"
        },
        "id": "NGx0efN6EaL_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(patience=3,monitor=\"val_loss\", restore_best_weights=True)\n",
        "\n",
        "fit = model.fit(train_generator,epochs=10 #(epoch count is reduced due to process length.)\n",
        ", validation_data=(test_generator) , callbacks=[early_stop])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-11T20:01:53.871321Z",
          "iopub.execute_input": "2025-03-11T20:01:53.871764Z",
          "iopub.status.idle": "2025-03-11T20:05:27.02061Z",
          "shell.execute_reply.started": "2025-03-11T20:01:53.871718Z",
          "shell.execute_reply": "2025-03-11T20:05:27.019698Z"
        },
        "id": "OxHeRpUjEaL_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LET’S TALK ABOUT SOME THEORETICAL TOPICS WHILE THE MODEL IS BEING TRAINED\n",
        "### 1. Data Augmentation\n",
        "* Scenario: We are training a model that distinguishes between cats and dogs for a classification problem. However, the number of training data is insufficient. In this case, it is very important to use data augmentation to prevent the model from overfitting.\n",
        "\n",
        "* What We Will Do: Data augmentation creates new images by manipulating the training data. This allows the model to learn more generally. We can augment data using the following operations:"
      ],
      "metadata": {
        "id": "Y2f1L5tjEaMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,           # Görselleri normalize et\n",
        "    rotation_range=40,        # Görselleri 40 dereceye kadar döndür\n",
        "    width_shift_range=0.2,    # Görselleri yatayda %20 kaydır\n",
        "    height_shift_range=0.2,   # Görselleri dikeyde %20 kaydır\n",
        "    shear_range=0.2,          # Görselleri eğik şekilde döndür\n",
        "    zoom_range=0.2,           # Görselleri %20 yakınlaştır\n",
        "    horizontal_flip=True,     # Görselleri yatayda çevir\n",
        "    fill_mode='nearest'       # Kayıp pikselleri en yakın değerle doldur\n",
        ")\n",
        "'''"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-11T19:59:00.163076Z",
          "iopub.status.idle": "2025-03-11T19:59:00.163414Z",
          "shell.execute_reply": "2025-03-11T19:59:00.163256Z"
        },
        "id": "NUX4SI6zEaMA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------"
      ],
      "metadata": {
        "id": "MReIlS5zEaMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Data Normalization\n",
        "* Scenario: Our training data may have different lighting conditions and color tones. This affects the model's learning process. In other words, it is important to bring the value of each pixel in the images to a standard level (normalize).\n",
        "\n",
        "* What We Will Do: Assuming that pixel values ​​are generally between 0 and 255, it is a good method to pull them between 0 and 1. This process allows the model to learn faster.\n",
        "it affects the process. In other words, it is important to bring the value of each pixel in the images to a standard level (normalize).\n",
        "\n",
        "* What We Will Do: Assuming that pixel values ​​are generally between 0 and 255, it is a good method to pull them between 0 and 1. This process allows the model to learn faster. This process allows the model to learn faster.\n",
        "\n",
        "*\n",
        " train_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "O3u6IZt0EaMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------"
      ],
      "metadata": {
        "id": "9Ze-32sjEaMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Forward and Backward Propagation\n",
        "* Scenario: We may need to use backpropagation to learn if the model is making the right prediction and to improve the parameters. In each training step, the model compares the predicted value with the real labels and updates the weights by backpropagating the error.\n",
        "\n",
        "* What We Will Do: This process is done with optimization algorithms (for example Adam or SGD).\n",
        "\n",
        "#### Why Do We Use It?\n",
        "\n",
        "* It tries to minimize the errors so that the model can make the right prediction.\n",
        "\n",
        "* Optimization algorithms provide better updating of the weights.\n",
        "\n",
        "---------------"
      ],
      "metadata": {
        "id": "dKvFWbyKEaMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.ReLU vs Leaky ReLU: Which One to Use in Which Situation?\n",
        "\n",
        "* ReLU: Provides fast learning and is generally used in datasets containing positive values. However, it can cause dead neuron problem.\n",
        "\n",
        "* Leaky ReLU: Prevents dead neuron problem and uses a small gradient in negative values. It is preferred in deep networks and places where vanishing gradient problem occurs.\n",
        "#### In short:\n",
        "* ReLU: For simple and fast learning.\n",
        "* Leaky ReLU: To prevent dead neuron and vanishing gradient problems."
      ],
      "metadata": {
        "id": "-XwhvKj8EaMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------"
      ],
      "metadata": {
        "id": "6mz315NBEaMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. What are Dead Neurons and Vanishing Gradients?\n",
        "\n",
        "* Dead Neuron: In activation functions like ReLU, negative inputs become zero. If a neuron consistently gives zero output, this neuron does not contribute to learning and becomes \"dead\". This can lead to the problem of learning nothing in some layers of the network.\n",
        "\n",
        "* Vanishing Gradient: In deep networks, the gradients become very small during backpropagation. In this case, the weight updates are not large enough and the model cannot learn. This is especially seen in activation functions like sigmoid and tanh. The advantage of ReLU is that it prevents this problem.\n",
        "-----------"
      ],
      "metadata": {
        "id": "02zYT93mEaMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. How to Understand Dead Neuron and Vanishing Gradient?\n",
        "\n",
        "* 1-) Dead Neuron Detection:\n",
        "\n",
        "During training, some neurons consistently give zero output. You can observe this on the activations. If most of the neurons in a layer have zero activation, there may be a dead neuron problem.\n",
        "\n",
        "Slight Meaning: If the accuracy of your model is increasing very slowly or is very low, there may be dead neurons.\n",
        "\n",
        "* 2-) Vanishing Gradient Detection:\n",
        "\n",
        "Tracing Gradients: During backpropagation, you can see that the gradients become very small. In this case, the weight updates are almost zero.\n",
        "\n",
        "Fast Loss Progress: If your model learns very slowly during training and the loss is very small, there may be a vanishing gradient problem.\n",
        "* How to Understand?\n",
        "\n",
        "When monitoring the performance of the model during training, a slow decrease in loss or a slow increase in accuracy could be a sign of dead neurons or a vanishing gradient."
      ],
      "metadata": {
        "id": "crxXiYdFEaMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-11T19:59:27.772602Z",
          "iopub.execute_input": "2025-03-11T19:59:27.772997Z",
          "iopub.status.idle": "2025-03-11T19:59:27.779194Z",
          "shell.execute_reply.started": "2025-03-11T19:59:27.772956Z",
          "shell.execute_reply": "2025-03-11T19:59:27.777733Z"
        },
        "id": "FfBAOAetEaMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Average Pooling vs Max Pooling: In Which Case Should Which One Be Used?\n",
        "\n",
        "##### Max Pooling:\n",
        "\n",
        "* It usually gives better results because it takes the highest value in each region, emphasizing important features.\n",
        "* It is especially preferred in tasks such as classification and object recognition. This helps the model to capture important details and emphasize local features.\n",
        "* In Which Case Should It Be Used?: For more detailed information extraction and strong overall performance, especially in cases where prominent features are prominent in the images.\n",
        "\n",
        "#### Average Pooling:\n",
        "\n",
        "* It provides smoother feature extraction because it takes the average of all values ​​in the region, which leads to less over-learning.\n",
        "\n",
        "This method is generally more resistant to noise, so it can be used when smoother features need to be extracted.\n",
        "\n",
        "* In Which Case Should It Be Used?: In cases where the model needs to take a less detail-oriented and more generalizing approach, for example, in more homogeneous data or in regularization requirements.\n",
        "#### In short:\n",
        "\n",
        "* Max Pooling: Cases where feature extraction is important and salient details are emphasized.\n",
        "* Average Pooling: Cases where more general feature extraction and over-learning should be avoided."
      ],
      "metadata": {
        "id": "iTRWxcnBEaMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------"
      ],
      "metadata": {
        "id": "PsB6jbTREaME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Valid Padding vs Same Padding: Which One Should Be Used In Which Case?\n",
        "\n",
        "* Valid Padding:\n",
        "\n",
        "There is a loss of dimension in the edge areas. In other words, the dimensions of the input image are reduced compared to the output.\n",
        "\n",
        "Advantage: It is faster in terms of calculation because the area to be processed is smaller.\n",
        "\n",
        "Use Case: If the output of the model (feature map) should be smaller and computational efficiency is at the forefront, valid padding is preferred.\n",
        "\n",
        "* Same Padding:\n",
        "\n",
        "The input and output dimensions are the same. In other words, zero padding is done on the edges (padding) so that the output image is the same as the dimensions of the input.\n",
        "\n",
        "Advantage: More information is preserved during feature extraction of the model and there is no loss of information in the deeper layers of the model.\n",
        "\n",
        "Use Case: If you want the output dimensions of the model to be close to the input dimensions and do not want to experience feature loss, same padding is preferred.\n",
        "#### How Do We Understand?\n",
        "\n",
        "* Valid Padding: If you don't care about the output size being smaller and want to process faster.\n",
        "\n",
        "* Same Padding: If you want the output size to be similar to the input and want the model to learn more details."
      ],
      "metadata": {
        "id": "2k0owQs2EaME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-11T20:00:48.762146Z",
          "iopub.execute_input": "2025-03-11T20:00:48.762528Z",
          "iopub.status.idle": "2025-03-11T20:00:48.768378Z",
          "shell.execute_reply.started": "2025-03-11T20:00:48.762504Z",
          "shell.execute_reply": "2025-03-11T20:00:48.767044Z"
        },
        "id": "p2F5QsQSEaME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. What Happens to the Model if the Kernel in Conv2D (5,5) is Enlarged?\n",
        "\n",
        "1-) Kernel Enlargement (For example, going from 3x3 to 5x5):\n",
        "\n",
        "* More calculations: Increasing the kernel size will cause you to have more parameters for each filter. This requires more calculations and can lead to longer training times.\n",
        "\n",
        "* More information collection: A larger kernel can collect more information by covering a larger area. This is especially useful in cases where more complex structures need to be learned.\n",
        "\n",
        "* Overfitting risk may increase because the model may try to learn too much detail and as a result may perform poorly on the test data.\n",
        "\n",
        "2-) Model Training Status:\n",
        "\n",
        "* Less Training: If you increase the kernel size and experience overfitting in your model, generalizability to the test data may decrease because your model has learned unnecessary much detail.\n",
        "\n",
        "* Overtraining: Increasing the kernel size can lead to more learning capacity, but if the right regularization strategies are not used, the model may take more time and require larger data\n",
        "\n",
        "  ### In summary:\n",
        "\n",
        "* Small kernel (3x3): Generally provides faster training and more efficient computations, learning details in smaller areas.\n",
        "\n",
        "* Large kernel (5x5 or 7x7): Learns information in larger areas, but model training may take longer and the risk of overfitting may increase.\n",
        "\n",
        "* Which kernel size to choose depends on the complexity of your dataset, the depth of the model, and your overall goals.\n",
        "---------------------"
      ],
      "metadata": {
        "id": "0MlArJjIEaME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LET'S EVALUATE THE MODEL"
      ],
      "metadata": {
        "id": "ASVbYSo-EaMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_test, y_test = next(test_generator)\n",
        "\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(true_classes, predicted_classes))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_classes, predicted_classes))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(true_classes, predicted_classes))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-11T20:05:28.885048Z",
          "iopub.execute_input": "2025-03-11T20:05:28.885414Z",
          "iopub.status.idle": "2025-03-11T20:05:29.094538Z",
          "shell.execute_reply.started": "2025-03-11T20:05:28.885386Z",
          "shell.execute_reply": "2025-03-11T20:05:29.093431Z"
        },
        "id": "qxsVminjEaMG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* If you get an error, you can check the code below."
      ],
      "metadata": {
        "id": "IkcYqerXEaMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "\n",
        "all_predictions = []\n",
        "all_true_classes = []\n",
        "\n",
        "\n",
        "for x_batch, y_batch in test_generator:\n",
        "    predictions = model.predict(x_batch)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    true_classes = np.argmax(y_batch, axis=1)\n",
        "\n",
        "\n",
        "    all_predictions.extend(predicted_classes)\n",
        "    all_true_classes.extend(true_classes)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(all_true_classes, all_predictions))\n",
        "print(\"Classification Report:\")\n",
        "\n",
        "print(classification_report(all_true_classes, all_predictions))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(all_true_classes, all_predictions))\n",
        "\n",
        "\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-11T20:05:35.623074Z",
          "iopub.execute_input": "2025-03-11T20:05:35.623436Z",
          "iopub.status.idle": "2025-03-11T20:05:35.629879Z",
          "shell.execute_reply.started": "2025-03-11T20:05:35.623408Z",
          "shell.execute_reply": "2025-03-11T20:05:35.628708Z"
        },
        "id": "IGJ8EDWkEaMG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I hope it was useful for you."
      ],
      "metadata": {
        "id": "9718mSDEEaMG"
      }
    }
  ]
}